\title{%
  Towards Perfectly Secure and Deniable Communication Using an NFC-Based 
  Key-Exchange Scheme
}
%\author{%
%  Daniel Bosk\inst{1}
%  \and
%  Martin Kjellqvist\inst{2}
%  \and
%  Sonja Buchegger\inst{1}
%}
%\institute{%
%  School of Computer Science and Communication,\\
%  KTH Royal Institute of Technology, SE-100\,44 Stockholm\\
%  Email: \email{\{dbosk,buc\}@kth.se}
%  \and
%  Department of Information and Communication Systems,\\
%  Mid Sweden University, SE-851\,70 Sundsvall\\
%  Email: \email{martin.kjellqvist@miun.se}
%}

\maketitle
\begin{abstract}
  The increased electronic communication of today has many advantages for the 
  users.
  But it also comes with a cost: reduction in privacy.
  There are many tools in use to increase privacy in the electronic setting, 
  e.g.~PGP and Off-the-Record.
  While providing some desirable privacy properties, these protocols get other 
  unexpected properties in the modern surveillance state.
  When one actor can collect, store and search Internet-wide transcripts of 
  communication, some of the usually desirable properties force us to commit to 
  our communication.
  Thus we lose the possibility of deniability.
  In this paper we first analyse the possibility for deniability under a strong 
  adversary, who has an Internet-wide transcript of the communication.
  I.e.~we assume a stronger adversary model.
  Secondly, we present a scheme which provides the desirable properties of 
  previous schemes, but with stronger deniability under the new adversary 
  model.
  Our scheme uses physical meetings for exchanges of large amounts of random 
  key-material via near-field communication and later uses this random data to 
  key a one-time pad for text-messaging.
  Finally we evaluate the practical feasibility of the suggested scheme.

  \keywords{%
    deniability, perfect secrecy, surveillance, strong adversary model, 
    key-exchange, near-field communication
  }
\end{abstract}

% XXX Weaken some statements
% - E.g. since the court trusts Eve -> if the court trusts Eve.
%   Otherwise you give reviewers cause for saying but that's not always true

\acresetall{}
\section{Introduction}

We have learned a lot about modern government surveillance from the Snowden 
revelations starting in 2013.
For our current treatment, the most interesting ones are the tapping of 
fibre-optic cables~\cite{fibretap}, the storage of all intercepted encrypted 
data~\cite{cryptostore}, the search~\cite{xkeyscore} and visualization 
capabilities~\cite{boundlessinformant} for all intercepted data.
It is not the details that are interesting, it is the fact that one actor can 
collect, store and search Internet-wide transcripts of communication.
This paper focuses on the possibility of deniability in this setting.

Today, \ac{GPG}~\cite{gpg}, \ac{OTR}~\cite{otr} and Text\-Secure 
\cite{textsecure} are among the popular services used for private 
communication.
\ac{GPG} provides standard asymmetric and symmetric encryption, intended for 
use with email.
In 2004, \citeauthor{otr2004}~\cite{otr2004} first described the \ac{OTR} due 
to limitations of deniability in \ac{GPG}.
The design goal of the protocol is to achieve strong privacy properties for 
users' online communication, the same properties as expected from 
a face-to-face conversation.
The main application at the time was \ac{IM}.
In 2010, OpenWhisperSystems adapted the \ac{OTR} messaging 
protocol~\cite{frosch2014secure} for use in the smartphone text-messaging app 
TextSecure.

The construction used for deniability in \ac{OTR}, and the derived protocols, 
is based on the principle <innocent until proven otherwise>.
While this holds true for most civil societies, it is not true everywhere.
There are circumstances in which the principle <guilty until proven otherwise> 
is applied instead.
For these circumstances, with an adversary that can record all network traffic, 
it is not possible to create any false witness (proof-of-innocence) due to the 
deterministic nature of the protocol.
In Sect.~\ref{sec:undeniability} we show that this allows an adversary with 
transcripts of all network traffic to verify any statements about the 
conversation using the transcripts.
To thwart this we need truly deniable encryption, as defined by 
\citet{deniablecrypt}, which means that we need to introduce some randomness.

\subsection{Our Contributions}

We start from systems like \ac{OTR}, but we assume a stronger adversary.
This stronger adversary model breaks some assumptions in \ac{OTR}-like 
protocols and removes the possibility for deniability.
We still want to achieve the same basic properties, e.g.~mutual authentication, 
but we also want to have stronger deniability.

In Sect.~\ref{sec:undeniability} we show that an adversary who can record all 
communication in a network can use the deterministic properties of commonly 
used mechanisms to reject lies about any communication.
In Sect.~\ref{sec:deniability} we outline what is needed to achieve 
deniability.

Our main contribution, however, is presented in Sect.~\ref{sec:otp-kx}.
We use \ac{NFC} in smartphones to exchange large-enough amounts of random data 
when two users physically meet.
Later, when the users are apart, this data is used to key a \ac{OTP} for use 
when communicating.
This is a work-around to achieve deniable communication.
As we know from \citet{ShannonSecrecy}, if we use the \ac{OTP} correctly, then 
our communication is even perfectly secure.
Our scheme is described in detail in Sect.~\ref{sec:otp-kx}.

To estimate the feasibility of this scheme we investigate
\begin{itemize}
  \item the order of magnitude of random data needed to be able to cover 
    everyday text-message conversation;

  \item if the \ac{NFC} transmission rates and the random number generation in 
    combination with the number of physical meetings can provide high enough 
    exchange rates in practice; and

  \item how the continuous key-generation in this scheme affects battery life 
    in the device.
\end{itemize}

We answer the first question by estimating the amount of private communication 
for some users.
The details can be found in Sect.~\ref{sec:NeededRandomness}.

We answer the second question by estimating the required number of physical 
meetings for the same users.
Since we have an estimate of the amount of exchanged randomness needed and the 
transmission rates for the \ac{NFC} protocol, we can estimate how many physical 
meetings and how long transfers are needed to cover the needs.
The details can be found in Sect.~\ref{sec:Meetings}.

For the third question, we estimate the battery usage by performing key 
generation and exchanges using different Android-based phones while monitoring 
the battery consumption.
The details can be found in Sect.~\ref{sec:Battery}.

Finally we present our conclusions and suggest future work in 
Sect.~\ref{sec:Conclusions}.


\section{The System and Adversary Models}

In this section we present the system and adversary model.
We start by presenting the system model.
Then we continue by presenting the adversary model and highlighting the 
differences compared to that of related protocols.

% - users have phones and can meet
% - the key-material can be securely stored and transferred from the phone
In our system model, we assume that each user has an \ac{NFC}-enabled 
smartphone.
This means that we have two communication channels: an \ac{NFC} channel and 
a public network-channel.
We will call them the private and public channel, respectively.
We can always use the public channel, but we can only use the private 
(\ac{NFC}) channel if we are in the same physical space.

We also assume that a user can, at least once, physically meet the party with 
whom they would like to communicate.
They must meet once before any electronic communication can be started.
In each meeting they exchange key-material.
We assume that a smartphone can generate cryptographically strong random data 
and that this random data is used as key-material.
Further, we assume that this key-material can be securely stored in the device.

% - phones are not compromised
% - Eve has transcript of internet traffic
% - Eve cannot listen on all NFC traffic
For the adversary model, we assume a stronger adversary, Eve.
Eve records all traffic in the public channel.
This means that she records all traffic for the entire Internet.
Thus Eve has a transcript of all communication that has taken place in the 
public channel and any future communication will also be entered into her 
transcript.
But Eve cannot record any communication in the private channel, since she is 
assumed to be in a different physical space.

We further assume that Eve is passive, i.e.~she cannot access the devices used 
in the communication at her own will.
Instead, she will accuse us based on the data and meta-data recorded in her 
transcript.
If Eve is trusted by the courts, then her transcript is also trusted.

%Finally, we assume that Eve is computationally bounded.


\section{Why Alice and Bob Currently Must Forget Their Conversation}
\label{sec:undeniability}

The security of today's popular services---\ac{GPG}, \ac{OTR} and 
TextSecure---rely on the standard cryptographic mechanisms.
These mechanisms provide strong security properties.
In this section we outline why some of these properties are too strong for 
deniability in the setting where the adversary has a transcript of all 
communications.

\ac{GPG} provides asymmetric and symmetric encryption intended to be used with 
email.
\citet{otr2004} have already presented arguments against \ac{GPG} (and 
\acl{PGP}, \acs{PGP}), but we will summarize them here.
If Alice wants to send a message \(m\) to Bob, then she will encrypt it for 
Bob's public key \(k_B\).
She will then create a signature for the resultant ciphertext \(c = \Enc_{k_B}( 
m )\) with her own private key \(k_A^{-1}\), i.e.~\(s = \Sign_{k_A^{-1}}( H(c) 
)\).
Alice will then send the ciphertext block and the signature to Bob, and this 
transaction will be recorded in Eve's transcript.
This scheme provides non-repudiation, i.e.~Alice can not deny having sent the 
message \(m\) at a later time and Bob can also prove to a third party that 
Alice sent \(m\).
Further, Eve can also prove that Alice sent \(c\), but she can only verify the 
plaintext \(m\) if Bob would reveal it to her.

In their paper, \citet{otr2004} suggested a scheme which does not have this 
problem: the \ac{OTR} messaging protocol.
This protocol provides authentication for Alice and Bob, so that they can trust 
they are talking to the right person.
But they can do no more than that, Bob can no longer prove to a third party 
what Alice has sent.
They accomplish this by a continuous use of the \ac{DH} key-exchange and 
a \ac{crMAC} based on symmetric keys.
Alice chooses a secret exponent \(a\) and Bob chooses a secret exponent \(b\).
Alice signs \(g^a\) and sends \[
  A\to B\colon g^a, \Sign_{k_A^{-1}}( g^a )
\] to Bob.
Bob conversely sends \(g^b, \Sign_{k_B^{-1}}( g^b )\) to Alice.
By this time they can both compute the secret shared-key \(k = g^{ab}\).
Let \(H_E\) and \(H_M\) be two cryptographically secure hash functions, used 
for deriving encryption and \ac{crMAC} keys, respectively.
When Alice wants to send the message \(m\) to Bob, she chooses a random 
\(a^\prime\) and sends \[
  A\to B\colon g^{a^\prime}, c = \Enc_{H_E( k )}( k )\oplus m,
  \MAC_{H_M( k )}( g^{a^\prime}, c )
\] to Bob.
Once she knows Bob has received the message she also sends the \ac{crMAC} key 
\(H_M( k )\) to Bob.
The next time Alice wants to send a message to Bob, she will use \(k^\prime 
= g^{a^\prime b}\).

Now, Bob can no longer prove to a third party what Alice has said.
This is due to the \ac{crMAC} being based on a secret key which Bob has access 
to.
Also, since the encryption is done in counter mode~\cite{blockmodes}, the 
ciphertext is malleable.
This means that flipping a bit in the ciphertext, yields the same flip in the 
plaintext.
Thus, anyone possessing the \ac{crMAC} key can modify the plaintext by flipping 
the bits in the ciphertext and then generate a new \ac{crMAC}.

\subsection{Verifying Who Sent What}

The arguments for forgeability using malleable encryption and publishing the 
\ac{crMAC} keys only hold if the adversary cannot trust the source of the 
transcript.
This more powerful Eve can ultimately trust the transcript since she collected 
it herself from the network.
And if the courts trust Eve, they also trust the transcript.

In this setting the forgeability property vanishes.
Eve knows that no one has modified the ciphertext, she recorded in her 
transcript as it left Alice and arrived to Bob.
She also recorded Alice publishing the \ac{crMAC} key used for the signature.
This allows Eve to use the \ac{crMAC} for each ciphertext to verify them.
She knows that Alice is the author of a message because she observes when Alice 
publishes the \ac{crMAC} key.
Thus, Eve also knows that no one has used the malleability property, because if 
they did, that action would be recorded in Eve's transcript.

\subsection{Verifying Encryption Keys}

Furthermore, Eve also learns some information about the key from the ciphertext 
and \ac{crMAC}.
Eve can use the \ac{crMAC} to discard false keys for the ciphertext.
Since Eve has \(s = \MAC_{H_M( k )}( c )\) for a ciphertext \(c\) recorded in 
her transcript, she can reject a key \(k^\prime\neq k\) by verifying that
\(\MAC_{H_M( k^\prime )}( c ) \neq s\).
Hence, by having the \ac{crMAC} key depend on the encryption key, we 
automatically decrease the number of spurious keys and thus also reduce our 
possibility for deniability.

\subsection{How Hard Is Deniability?}
\label{sec:HardnessOfDeniability}

As suggested above, we have difficulty achieving deniability.
This is illustrated by the following equations.
Assume
\begin{equation*}
  \Enc_{H_E(k)}( m ) = c = \Enc_{H_E(k^\prime)}( m^\prime )
\end{equation*}
and \(k\neq k^\prime\), then
\begin{equation*}
  \Pr\left[
    \MAC_{H_M(k)}( c ) = \MAC_{H_M(k^\prime)}( c )
  \right]
  \approx
  \Pr\left[ H_M(k) = H_M(k^\prime) \right].
\end{equation*}
I.e.~our chance of lying about the key \(k\), replacing it with a key 
\(k^\prime\), is reduced to finding a collision for the hash function \(H_M\).
(There is also the negligible probability of \(\MAC_x(c) = \MAC_{x^\prime}(c)\) 
for \(x\neq x^\prime\) to consider.)

Furthermore, we find the key \(k^\prime\) by finding the preimage of \(H_E( 
k^\prime )\).
And if the encryption system \(\Enc\) is a trap-door permutation, then we will 
have to break that first, just to find \(H_E( k^\prime )\) before we can 
attempt finding its preimage.


\section{Requirements for Deniability}
\label{sec:deniability}

To be able to get deniability in our given scenario, Alice and Bob need to be 
able to modify the plaintext without modifying the ciphertext.
They also need a \ac{crMAC} key independent from the encryption key.
Then they can change the encryption key and the plaintext, but the ciphertext 
and \ac{crMAC} remains the same.

\citeauthor{deniablecrypt} gave the original formal definition of deniable 
encryption in their seminal paper \cite{deniablecrypt}.
We will give their definition of sender-deniable encryption for shared-key 
schemes here.
\begin{definition}[Shared-key sender-deniable encryption]
  \label{def:DeniableEnc}
  A protocol \(\pi\) with sender \(S\) and receiver \(R\), and with security 
  parameter \(n\), is a shared-key sender-deniable encryption protocol if:
  \begin{description}
    \item[Correctness] The probability that \(R\)'s output is different than 
      \(S\)'s output is negligible (as a function of \(n\)).

    \item[Security] For any \(m_1, m_2\in M\) in the message-space \(M\) and 
      a shared-key \(k\in K\) chosen at random from the key-space \(K\), then 
      we have \(\Pr[ \Enc_k( m_1 ) = c ] \approx \Pr[ \Enc_{k^\prime}( m_2 
      ) = c ].\)

    \item[Deniability] There exists an efficient <faking> algorithm \(\phi\) 
      having the following property with respect to any \(m_1, m_2\in M.\)
      Let \(k, r_S, r_R\) be uniformly chosen shared-key and random inputs of 
      \(S\) and \(R\), respectively, let \(c = \Enc_{k, r_S, r_R}( m_1 )\) and 
      let \((k^\prime, r_S^\prime) = \phi( m_1, k, r_S, c, m_2 ).\)
      Then the random variables \[
        ( m_2, k^\prime, r_S^\prime, c ) \text{ and }
        ( m_2, k, r_S, \Enc_{k, r_S, r_R}( m_2 ) )
      \] are distinguishable with negligible probability in the security 
      parameter \(n\).
  \end{description}
\end{definition}
This means that given a ciphertext \(c = \Enc_k( m )\) and a false plaintext 
\(m^\prime\), there exists a polynomial-time algorithm \(\phi\) such that 
\(\phi( c, m^\prime ) = k^\prime\) yields a key \(k^\prime\) and \(m^\prime 
= \Dec_{k^\prime}( c )\).
As we illustrate in Sect.~\ref{sec:HardnessOfDeniability}, there exists no such 
polynomial-time algorithm \(\phi\) for \ac{OTR} or \ac{GPG}.
%If one existed, then it could be used to break other security mechanisms.

One encryption system for which the algorithm \(\phi\) is trivial is the 
\ac{OTP}.
\begin{definition}[One-Time Pad]
  \label{def:OTP}
  Let \(M = K = (\Z_2)^n\).
  Then let \(m\in M\) be a message in the message-space \(M\), let \(k\in K\) 
  be a uniformly chosen key in the key-space \(K\).
  Then we define \[
    \Enc_k( m ) = m\oplus k \text{ and } \Dec_k = \Enc_k.
  \]
\end{definition}
\citet{ShannonSecrecy} proved that this scheme is perfectly secret.
But this requires that the key \(k\) is as long as the message \(m\).
The key must be uniformly chosen, i.e.~never reused.
This is why this scheme is usually considered impractical.

We can easily see, and it is also pointed out in \cite{deniablecrypt}, that the 
\ac{OTP} fulfils Def.~\ref{def:DeniableEnc}.
We can simply define \(\phi( m_2, c ) = m_2\oplus c\) and this would yield 
\(k^\prime\) such that \[
  \Dec_{k^\prime}( c ) = c\oplus k^\prime = c\oplus ( m_2\oplus c ) = m_2.
\]

%If \(\Enc\) used in \ac{OTR} would be replaced with \ac{OTP}, then we can 
%easily compute the false key \(k^\prime\) from a given plaintext-ciphertext 
%pair.

We also want to resolve the problem of the \ac{crMAC} being a witness for the 
correct key.
The problem in the previous schemes is that the \ac{crMAC} key is derived from 
the same master key as the encryption key.
Instead of deriving the encryption key and the \ac{crMAC} key by using two 
different key-derivation functions on the same master key, we have to use 
information-theoretically independent keys.

We still want authenticated encryption though.
\citet{authenc} proved that first encrypting the plaintext and then generating 
a \ac{crMAC} for the ciphertext, always provides secure authenticated 
encryption.
Since this authenticates the ciphertext, and not the plaintext, it will not 
interfere with our deniability.
This way, when using the \ac{OTP} we can keep the \ac{crMAC} key fixed while 
adapting the encryption key to our new plaintext, then hand the keys for both 
\ac{crMAC} and encryption to the adversary as a (false) witness.


\section{Achieving Deniability}
\label{sec:otp-kx}

% XXX move emphasis from quantification to security proofs
% - now there's a lot of emphasis on the quantification.  Once you have more of 
% a protocol description and proof (sketch), this should balance out. Point out 
% that the measurements and calculations are there just to get an idea of 
% whether this is feasible at all, and that the numbers will change with 
% datasets, user behaviour, device, etc.

Due to the deniability requirements outlined above, the randomness used for 
encryption cannot be extended by a \ac{PRNG}: if we do, then we are in the same 
situation as when we were using a trap-door permutation---we cannot efficiently 
find a seed to the \ac{PRNG} which yields a stream that decrypts the ciphertext 
to the desired plaintext.
Instead we generate randomness continuously and then exchange it using the 
\ac{NFC} functionality of smartphones.
This way we can use the everyday chance-encounters for exchanging the generated 
randomness when we meet, and then use it to key the \ac{OTP} scheme when 
physically apart.

\subsection{The Protocol}

% XXX describe protocol in more detail
% - still rely on OTR?
% - who sends what (illustrate with a protocol diagram)
% - we can still publish the MAC key, so that NSA cannot prove to third party
% - what properties do we get, include a security proof
% - talk about what happens if you can't meet or run out of randomness. You 
% should be able to fall back on the original otr and never be worse off than 
% that
% - perhaps you can show that in the protocol diagram or in pseudocode

Alice and Bob want to communicate using this protocol.
This randomness is then removed from the pool and associated with a known user.
The received randomness is also associated with the same user.
The protocol is illustrated in Fig.~\ref{fig:Protocol}.

From a user perspective, putting two phones together <charges the encryption 
tool>.
This is probably a good metaphor to build on, since it builds on the mental 
model of a battery.
Users are already familiar with this model, and thus, when running low on 
randomness, fewer messages should be exchanged until another physical meeting 
can be arranged to <charge> the tool again.

We should have more details about the protocol \dots

A detailed security proof should go somewhere here, or at least a sketch and 
details in appendices \dots

\marginnote{\raggedright
  This section is far from done \dots
}

\begin{figure}
  \centering
  \begin{sequencediagram}
    \newinst{A}{Alice}
    \newinst[1]{E}{Eve}
    \newinst[1]{B}{Bob}

    \mess{A}{Private channel}{B}
    \node[anchor=east] at (mess from) {$k_i, k_{i+1}, \ldots, k_j$};

    \begin{sdblock}{Public channel}{Eve records this traffic}
      \mess{A}{}{E}
      \node[anchor=east] at (mess from)
      {\shortstack{$\Enc_{k_i}( m_{i^\prime} ) = c_{i^\prime}$, \\ 
      $\MAC_{k_{i+1}}( c_{i^\prime} )$}};
      \prelevel
      \mess{E}{}{B}

      \mess{B}{}{E}
      \node[anchor=west] at (mess from)
      {\shortstack{$\Enc_{k_{i+2}}( m_{i^\prime+1} ) = c_{i^\prime+1}$, \\
      $\MAC_{k_{i+3}}( c_{i^\prime+1} )$}};
      \prelevel
      \mess{E}{}{A}
    \end{sdblock}

  \end{sequencediagram}
  \caption{%
    A sequence diagram illustrating the protocol.
  }
  \label{fig:Protocol}
\end{figure}

\subsection{Implementation and Evaluation}

We have developed an app\footnote{%
  % XXX fix github URL
  The source code is available at URL \url{https://github.com/X/}.
} for Android devices which implements the above ideas.
It generates randomness continuously in the background to build up a pool of 
randomness.
It can also exchange this randomness with another phone over \ac{NFC}.

To estimate the feasibility of this scheme, we investigate the amount of 
randomness needed and how much randomness we can generate 
(Sect.~\ref{sec:NeededRandomness}), the required and possible transfer times 
over \ac{NFC} (Sect.~\ref{sec:Meetings}), and finally how this scheme affects 
the battery consumption of the smartphone (Sect.~\ref{sec:Battery}).
The methodology and results are given in each respective section below.

\subsection{The Amount of Randomness Needed}
\label{sec:NeededRandomness}
Since we use the \ac{OTP}, we need as much key material for encryption as we 
have plaintext.
We need some additional key-material for the \acp{crMAC}, e.g.~128--256 bits 
per sent message.
Thus we can estimate the total amount of randomness needed by estimating the 
exchange rate of plaintext.
To do this we analyse the Enron email dataset\footnote{%
  % XXX fix github URL
  The source code for the data analysis described below is available at URL 
  \url{https://github.com/X/}.
}.

We are interested in personal communication, i.e.~we are not interested in 
newsletters and the like.
We are not interested in attachments either, so we discard those.
To filter out the newsletter category of messages, we rely on emails found in 
the users <sent> directory, since these are emails sent by real users.
Although we were not interested in newsletter-like emails, the sent directories 
might include forwarded newsletters.
However, we argue that these should be included since the user actively wanted 
to tell someone else about the content.

%Since we are using the \ac{OTP}, we also use key material for the replies.
%We thus also include the received replies to the sent emails.
%The rationale for this is that received replies are not necessarily from people 
%within the Enron company, but the emails are written by real users and should 
%thus be included to give us more accurate data.

Since this dataset contains a mix of corporate and private emails, and is 
fairly small, it is hard to draw any general conclusions from it.
But our main goal is to get an estimate of user communication to see whether 
our scheme is completely infeasible or not.
So the Enron dataset is just one example, communication using other media, 
e.g.~text messages rather than email, would probably differ.

\begin{pycode}[random]
import math
import sqlite3
import pathlib
import sys
import decimal

sys.path.insert( 0, "mailstat" )
import mailstat
#import libsci

metadata = sqlite3.connect( "enron-sent.sqlite3" )
prectime = decimal.Decimal( "0.1" )
precdata = decimal.Decimal( "1000" )

mean_msg_size, stddev_msg_size = \
  mailstat.mean_message_size( metadata )
mean_msg_size = mean_msg_size.quantize( precdata )
stddev_msg_size = stddev_msg_size.quantize( precdata )

mean_msg_freq, stddev_msg_freq = ( decimal.Decimal(20), decimal.Decimal(5) )
#  mailstat.mean_message_frequency( metadata )
mean_msg_freq = mean_msg_freq.quantize( precdata )
stddev_msg_freq = stddev_msg_freq.quantize( precdata )

mean_contacts, stddev_contacts = \
  mailstat.mean_number_of_contacts( metadata )
mean_contacts = mean_contacts.quantize( precdata )
stddev_contacts = stddev_contacts.quantize( precdata )

data_per_day = ( mean_msg_size + stddev_msg_size ) * mean_msg_freq
\end{pycode}

\marginnote{\raggedright
  \textbf{Note:}
  The numbers in this and the following sections are preliminary.
  We have not yet analysed the dataset in detail to discover any possible 
  problems, e.g.~that replies usually include the history of the conversation.
  This is also the reason why they are rounded to have one or no decimals, 
  rather than rounded according to their number of significant digits.
  All numbers will be rounded to the number of significant digits in the final 
  version of the paper.
}
In the Enron dataset, we found that the average message was
\(\unit{\py[random]{mean_msg_size}}{\byte}\)
excluding any headers and attachments.
The standard deviation was
\(\unit{\py[random]{stddev_msg_size}}{\byte}.\)
The large standard deviation can probably be explained by the data being 
emailed:
If a conversation requires a few rounds, then the previous messages accumulate 
in the body of the email as included history.

We also found that the average user communicates with
\(\py[random]{mean_contacts}\)
other users.
The standard deviation was
\(\py[random]{stddev_contacts}.\)
This means that an <extreme> user has approximately
\(\py[random]{(mean_contacts 
+ 3*stddev_contacts).quantize(decimal.Decimal(10))}\)
users to exchange keys with.

\reversemarginpar
\marginnote{\raggedright
  \textbf{Note:}
  We have not yet estimated this number from the dataset.
  We chose the number \py[random]{mean_msg_freq} as a reasonably high guess.
  The estimated value from the dataset will be available in the final version 
  of the paper.
}
\reversemarginpar
If a user sends
\(\py[random]{mean_msg_freq}\)
messages per day, then we need on average less than
\(\unit{\py[random]{(data_per_day/1024).quantize( 10 )}}{\kibi\byte}\)
per day.

When we use Android's <SecureRandom> to generate our randomness, we can 
generate enough amounts of random data.
Some research \cite{AndroidLowEntropyMyth,JavaRandomness} suggest that 
<SecureRandom> under certain circumstances uses a low entropy seed.
However, the documentation states that SecureRandom can be relied upon for 
cryptographic purposes.
Thus the security in using SecureRandom for the \ac{OTP} must be investigated 
further.

\subsection{The Number of Meetings and Transfer Time}
\label{sec:Meetings}
From the above analysis, we know the average amount of data communicated 
between users per day.
We also know that the \ac{NFC} protocol can achieve a transmission rate of up 
to \unit{424}{\kilo\bit\per\second}~\cite{NFCController}.
In Tab.~\ref{tbl:MeetingsTradeoff} we tabulate how often two users meet 
compared to how much key-material they would need on average until the next 
meeting and how long time this data would take to transfer using \ac{NFC}.
The times provided does not include the setup of the \ac{NFC} radio channel, 
only actual transmission is considered. The setup phase takes about 5 seconds 
on the tested devices.

% XXX improve visualization of the data
% - Mitra had a good suggestion
\begin{table}
  \centering
  \caption{%
    The table illustrates how the frequency of the key-exchanges affects the 
    required time for each key-exchange.
    Less frequent exchanges requires larger exchanges and, hence, more time.
  }
  \label{tbl:MeetingsTradeoff}
  \begin{pycode}[random]
print( r"""
\begin{tabular}{lrr}
  Exchange &
  Time (\second) &
  Key-material (\kibi\byte) \\
  \toprule
""" )

timespans = {
  1 : "Daily",
  7 : "Weekly",
  30 : "Monthly",
  60 : "Bimonthly",
  365 : "Annually"
}

for i in sorted( timespans.keys() ):
  needed_data = ( data_per_day * i ).quantize( precdata )
  needed_time = needed_data / ( decimal.Decimal( 424 ) * 1000 / 8 )
  needed_time = needed_time.quantize( prectime )
  print( r"%s & \(%s\) & \(%s\) \\" % \
  ( timespans[i],
    ( needed_time ).quantize( prectime ),
    ( needed_data/1024 ).quantize( precdata )
    ) )

print( r"""
  \bottomrule
\end{tabular}
""" )
  \end{pycode}
\end{table}

Considering this, we can see that a user needs to spend an order of 10s of 
seconds per day doing key-exchanges.
This number is divided among the contacts with whom the user communicates.
More frequently communicating contacts will require a larger part of the 
key-exchanges.

\subsection{The Battery Consumption}
\label{sec:Battery}
% XXX fix the battery consumption section
To estimate the effects on battery consumption we find a typical RF-active 
rating of \unit{60}{mA} for the NFC chip \cite{NFCController}. The battery 
effects of this is negligible and on the order of $2$\textperthousand of the 
battery charge at the considered usages.

To estimate the effects on battery consumption we first build a baseline.
For this we used the Android systems build-in power-consumption estimates.
We used one phone as a reference and two others running the app implementing 
our scheme.

For the component generating the randomness, tests were performed where we 
generated the annual demand of key-material. This provided no indication of 
battery drain. The CPU load was measured at $2\%$, the IO load was measured at 
$15\%$. 

\section{Conclusions}
\label{sec:Conclusions}

% XXX complete the conclusions
\dots

The effects on battery life under the considered use is not a limiting factor 
in neither the generation of the key-material nor the transmission of the 
key-material. 

A typical exchange of key material requires less than $\unit{10}{s}$ to 
complete. The transmission rates are not a useability concern in our model. 

Considering the location-based privacy, we would probably like to keep it in 
flight-mode.
Then we would save power which can later be used for the exchange.

The method for estimating the amount of communication can be better.
It depends on the type of communication, e.g.~corporate emails differs from 
personal text-messaging.
Due to this it might better to evaluate this from the usage point.
To better estimate communication needs for private individuals, it might be 
better to use text-messages (SMSs).

The design of the NFC API is hindering the flexibility of the solution. A few 
concerning points are
\begin{itemize}
\item There is no mechanism in which to stream data over NFC. This is desirable 
from a usability standpoint of the app. In particular with regards to 
interrupted transmissions. This might be solved by a more innovative 
implementation. 
\item The files currently has to reside on a publicly readable filesystem.  
	This is a concern for the integrity of the key-material.
\item The beamed files can be intercepted by a malicious app competing for the 
	beamed files.
\end{itemize}


\subsection{Future Work}

There are several interesting directions to follow from this work.
First, we can argue the need for deniability as compared to not being able to 
reveal any keys.
An interesting first step in this direction would be to conduct a study with 
users: what is the users' perception of deniability, what is more convincing?
It would also be interesting to contrast this by looking into game theory to 
see what can be said about the behaviour of a probable liar: do we gain any 
credibility using this deniable scheme over simply refusing to disclose the 
key?
What are the differences if we have a rational adversary compared to an 
irrational one?
Finally, there is the legal perspective, which could probably also benefit from 
exploring these questions.

Another direction, into usable security and privacy, would be to study suitable 
metaphors and mental models for this kind of system.
We suspect that the mental model of <charging deniability> when we exchange 
randomness is good, i.e.~that it does not lead to any contradictory behaviours 
which might put the user's security and privacy at risk.
Our guess is that this is more intuitive than e.g.~asymmetric encryption.

Finally, to support the user, it would be interesting to have a <budget> 
algorithm for the exchanges.
This algorithms would take into account the users' average communication rate 
and the users' average exchange frequencies, use these data to support the user 
in planning for future key-exchanges if the communication pattern changes or 
deviates from normal.


\subsubsection*{\ackname}

%This work was funded by the Swedish Foundation for Strategic Research grant SSF 
%FFL09-0086 and the Swedish Research Council grant VR 2009-3793.
We would like to thank the anonymous reviewers for valuable feedback.


\printbibliography{}

